

# CMPS 2200 Assignment 1

**Name:**_________________________


In this assignment, you will learn more about asymptotic notation, parallelism, functional languages, and algorithmic cost models. As in the recitation, some of your answer will go here and some will go in `main.py`. You are welcome to edit this `assignment-01.md` file directly, or print and fill in by hand. If you do the latter, please scan to a file `assignment-01.pdf` and push to your github repository. 
  
  

1. (2 pts ea) **Asymptotic notation** (12 pts)

  - 1a. Is $2^{n+1} \in O(2^n)$? Why or why not? 
.   
    Yes, $2^{n+1} is in O(2^n)$, because $2^{n+1} <= 2 * (2^n)$, meaning
    $2^{n+1} will never exceed 2 * (2^n)$.
.  
.  
.  
. 
  - 1b. Is $2^{2^n} \in O(2^n)$? Why or why not?     
.  
.  No, $2^{2^n} is not in O(2^n)$, because the growth rate of $2^{2^n} is 
   far greater than that of (2^n)$, meaning f(n) will eventually exceed  c * g(n).
.  
.  
.  
  - 1c. Is $n^{1.01} \in O(\mathrm{log}^2 n)$?    
.  
.  No, $n^{1.01} is not in O(\mathrm{log}^2 n)$.
.  
.  

  - 1d. Is $n^{1.01} \in \Omega(\mathrm{log}^2 n)$?  
.  
.  Yes, $n^{1.01} is in \Omega(\mathrm{log}^2 n)$.
.  
.  
  - 1e. Is $\sqrt{n} \in O((\mathrm{log} n)^3)$?  
.  
.  No, $\sqrt{n} is not in O((\mathrm{log} n)^3)$.
.  
.  
  - 1f. Is $\sqrt{n} \in \Omega((\mathrm{log} n)^3)$?  
.  
    No, $\sqrt{n} is not in \Omega((\mathrm{log} n)^3)$.


2. **SPARC to Python** (12 pts)

Consider the following SPARC code of the Fibonacci sequence, which is the series of numbers where each number is the sum of the two preceding numbers. For example, 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610 ... 
$$
\begin{array}{l}
\mathit{foo}~x =   \\
~~~~\texttt{if}{}~~x \le 1~~\texttt{then}{}\\
~~~~~~~~x\\   
~~~~\texttt{else}\\
~~~~~~~~\texttt{let}{}~~(ra, rb) = (\mathit{foo}~(x-1))~~,~~(\mathit{foo}~(x-2))~~\texttt{in}{}\\  
~~~~~~~~~~~~ra + rb\\  
~~~~~~~~\texttt{end}{}.\\
\end{array}
$$ 

  - 2a. (6 pts) Translate this to Python code -- fill in the `def foo` method in `main.py`  

  - 2b. (6 pts) What does this function do, in your own words?  

.  
.  This function starts by taking a given integer input, and then recursively    generating a fibonacci sequence based on said input. The base case is when x <= 1, in which case no more fibonacci numbers can be generated. Otherwise, the sum of the previous 2 fibonacci numbers is taken and then returned as the next number in the sequence, and the function is recursively called again until the base case is met.
.  
.  
.  
.  
.  
.  
  

3. **Parallelism and recursion** (26 pts)

Consider the following function:  

```python
def longest_run(myarray, key)
   """
    Input:
      `myarray`: a list of ints
      `key`: an int
    Return:
      the longest continuous sequence of `key` in `myarray`
   """
```
E.g., `longest_run([2,12,12,8,12,12,12,0,12,1], 12) == 3`  
 
  - 3a. (7 pts) First, implement an iterative, sequential version of `longest_run` in `main.py`.  

  - 3b. (4 pts) What is the Work and Span of this implementation?  

.  The work of this implementation is O(n), with n being the length of the input list. This is because the entire list is interated through once, with constant time operations. 
.  
.  
.  The span of this implementation is also O(n) in the worst case. This is because the depth of the tree is in this case directly proportional to the size of input, as each key of the list must be explored sequentially. 
.  
.  
.  
.  
.  
  - 3c. (7 pts) Next, implement a `longest_run_recursive`, a recursive, divide and conquer implementation. This is analogous to our implementation of `sum_list_recursive`. To do so, you will need to think about how to combine partial solutions from each recursive call. Make use of the provided class `Result`.   

  - 3d. (4 pts) What is the Work and Span of this sequential algorithm?  
.  
.  The work of this algorithm is O(n logn) because the algorithm works by recursively dividing the array into halves, with each division taking O(logn) time. This is then multiplied by the constant time operations for each division, or n.
.  
.  
.  
.  
. The span of this algorithm is also O(n logn). This is because the tree consists of O(logn) levels, because each level is a division by 2 of the original input. However, there is also span of O(n) at each individual level, as each level processes all array elements. Multiplying these two gives us our final span of O(n logn).  
.  
.  
.  
.  

  - 3e. (4 pts) Assume that we parallelize in a similar way we did with `sum_list_recursive`. That is, each recursive call spawns a new thread. What is the Work and Span of this algorithm?  

.  
.  In this case of parallelizing the algorithm, the work remains the same as above, at O(n logn). This is because each level processes O(n) elements, and there are O(logn) levels.
.  
.  
. However, span is reduced by parallelizing this algorithm to O(logn). This is because parallel threads can be executed independently of each other, reducing the depth of the tree from O(n logn) to simply O(logn).
.  
.  
.  

